SQIitemcorr2 <- polychoric(items_withoutQI2,smooth=TRUE,global=TRUE,weight=NULL,progress=TRUE,na.rm=TRUE, delete=TRUE)
items_withoutQI2 <- as_tibble(select(itemsonly,c(1:4,13:54)))
#get cleaned data if session looses environment
FlanaganFinalData <- read.csv("FlanaganFinalData.csv",header = TRUE)
library(psych)
library(corrplot)
library(polycor)
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(6:59)))))
QI2_items <- as_tibble(select(allitems,c(5:12)))
trns_items <- as_tibble(select(allitems,c(1:4,13:54)))
rm(all_items)
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(6:59)))))
QI2_items <- as_tibble(select(all_items,c(5:12)))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
trns_items_correlations <- polychoric(trns_items,smooth=TRUE,global=TRUE,weight=NULL,progress=TRUE,na.rm=TRUE, delete=TRUE)
trns_items_corrplot <- corrplot(trns_items_correlations$rho,type = "lower",method="number")
rm(trns_items_correlations)
rm(trns_items_corrplot)
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:59)))))
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:50)))))
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
rm(QI2_items)
rm(trns_items)
View(all_items)
QI2_items <- as_tibble(select(all_items,c(5:12)))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
trns_items_correlations <- polychoric(trns_items,smooth=TRUE,global=TRUE,weight=NULL,progress=TRUE,na.rm=TRUE, delete=TRUE)
trns_items_corrplot <- corrplot(trns_items_correlations$rho,type = "lower",method="number")
#Check Factorability of the data
KMOSQI <- KMO(trns_items$rho)
#Check Factorability of the data
KMOSQI <- KMO(trns_items) %>% select(rho)
#Check Factorability of the data
KMOSQI <- KMO(trns_items)
print(KMOSQI)
#Check Factorability of the data
KMO_trns <- KMO(trns_items)
rm(KMOSQI)
corrplot_trns(KMOSQI$ImCov,type= "lower",method = "number")
corrplot_trns(KMO_trns$ImCov,type= "lower",method = "number")
trns_corrplot <- corrplot(KMO_trns$ImCov,type= "lower",method = "number")
rm(trns_corrplot)
trns_anticorr <- corrplot(KMO_trns$ImCov,type= "lower",method = "number")
rm(trns_items_corrplot)
#all besides QI2
trns_items_correlations <- polychoric(trns_items,smooth=TRUE,global=TRUE,weight=NULL,progress=TRUE,na.rm=TRUE, delete=TRUE)
trns_items_corrplot <- corrplot(trns_items_correlations$rho,type = "lower",method="number")
o
trns_items_corrplot <- corrplot(trns_items_correlations$rho,type = "lower",method="number")
Bart <- cortest.bartlett(KMO_trns$rho,n=618)
Bart <- cortest.bartlett(KMO_trns$rho)
Bart <- cortest.bartlett(trns_items_correlations)
Bart <- cortest.bartlett(trns_items_correlations$rho)
Bart <- cortest.bartlett(trns_items_correlations$rho,n=618)
#PCA
trns_PCA <- prcomp(trns_items,center=TRUE,scale. = TRUE)
eigenvaluesPCA <- as_tibble(trns_PCA$sdev^2) #squares of the stdev of the principal components provide eigenvalues
loadingsPCA <- as_tibble(trns_PCA$rotation)
rm(eigenvaluesPCA)
rm(loadingsPCA)
#Check Factorability of the data
trns_KMO <- KMO(trns_items)
trns_anticorr <- corrplot(KMO_trns$ImCov,type= "lower",method = "number")
trns_Bart <- cortest.bartlett(trns_items_correlations$rho,n=618)
RM(KMO_trns)
rn(KMO_trns)
rm(KMO_trns)
rm(Bart)
install.packages("FactoMineR")
library(FactoMineR)
principal(trns_items_correlations,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly")
principal(trns_items_correlations$rho,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly")
trns_PCA <- principal(trns_items_correlations$rho,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly")
trns_PCA$values
trns_PCA <- principal(trns_items_correlations$rho,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly",
rotate="varimax"
trns_PCA$values
trns_PCA <- principal(trns_items_correlations$rho,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly",
rotation="varimax"
trns_PCA <- principal(trns_items_correlations$rho,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly",
rotation="varimax")
trns_PCA <- principal(trns_items_correlations$rho,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly",
rotation="varimax")
trns_PCA$values
screeplot(trns_PCA$values)
trns_PCA$values
trns_PCA$rotation
trns_PCA$communality
trns_PCA_eigenvalues <- trns_PCA$values
rm(trns_PCA_eigenvalues)
trns_PCA_eigenvalues <- as_tibble(trns_PCA$values)
View(trns_PCA_eigenvalues)
trns_PCA <- principal(trns_items_correlations$rho,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly",
rotate="varimax")
trns_PCA <- principal(trns_items_correlations$rho,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly")
trns_PCA_eigenvalues <- as_tibble(trns_PCA$values)
principal(trns_items_correlations$rho,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly")
principal(trns_items_correlations$rho,
nfactors = 1,
residuals = TRUE,
rotate = "none",
n.obs = 618,
covar = TRUE,
cor = "poly")
trns_PCA_loadings <- as_tibble(trns_PCA$loadings)
#Example of feature extraction using PCA
library(data.table)
library(dplyr)
detach("package:corrplot", unload = TRUE)
detach("package:FactoMineR", unload = TRUE)
detach("package:forcats", unload = TRUE)
library(forcats)
detach("package:ggplot2", unload = TRUE)
library(ggplot2)
detach("package:lavaan", unload = TRUE)
detach("package:polycor", unload = TRUE)
detach("package:psych", unload = TRUE)
#Example of feature extraction using PCA
library(data.table)
library(dplyr)
library(datasets)
library(ggplot2)
data <- read.csv("PCAtestdata.csv")
data <- read.csv("PCAtestdata.csv")
data2 <- copy(data)
data2 <- pizza[,brand := NULL] #Assign a fixed value to new variable of "pizza".
data2 <- pizza[, brand := NULL] #Assign a fixed value to new variable of "pizza".
data2$target <- NULL #Assign target variable
data2$target <- NA #Assign target variable
data <- read.csv("PCAtestdata.csv")
data2 <- copy(data)
data <- read.csv("PCAtestdata.csv")
data2 <- copy(data)
data2 <- data2[,brand := NULL] #Assign a fixed value to new variable of "pizza".
data <- read.csv("PCAtestdata.csv")
data <- data.table(read.csv("PCAtestdata.csv"))
rm(data2)
pizzas <- copy(data)
pizzas <- pizza[, brand := NULL]
pizzas <- copy(data)
pizzas <- pizzas[, brand := NULL]
pca <- prcomp(pizzas, scale. = TRUE)
pizzas <- pizzas[, brand := NULL]
pca_1_2 <- data.frame(pca$x[, 1:2])
plot(pca$x[,1], pca$x[,2])
data <- data.table(read.csv("PCAtestdata.csv"))
data <- data[1:87,]
pizzas <- copy(data)
pizzas <- pizzas[, brand := NULL] #make target null because we want the analyses to tell us the different types
pca <- prcomp(pizzas, scale. = TRUE)
pca_1_2 <- data.frame(pca$x[, 1:2])
plot(pca$x[,1], pca$x[,2])
#Calculate the percentage of variation within each principal component
pca_var <- pca$sdev^2 #get variance
pca_var_perc <- round(pca_var/sum(pca_var)*100,1)
barplot(pca_var_perc,main= "PC Variation Plot", xlab="Principal Components", ylab="Percentage of Variance",ylim = c(0,100))
PC1 <- pca$rotation[,1]
PC1_scores <- abs(PC1)
PC1_scores_ordered <- sort(PCA1_scores,decreasing = TRUE)
#assign weights to features in each PCA (loadings), with an array of loadings for each PC being an Eigenvector
PC1 <- pca$rotation[,1]
PC1_scores <- abs(PC1)
PC1_scores_ordered <- sort(PCA1_scores,decreasing = TRUE)
PC1_scores_ordered <- sort(PC1_scores,decreasing = TRUE)
names(PC1_scores_ordered)
ggplot(data,aes(x=data$cal,y=data$mois,color = data$brand)) +
geom_plot() +
labs(title = "Pizza brands by two most important differentating characteristics")
ggplot(data,aes(x=data$cal,y=data$mois,color = data$brand)) +
geom_point() +
labs(title = "Pizza brands by two most important differentating characteristics")
#get cleaned data if session looses environment
FlanaganFinalData <- read.csv("FlanaganFinalData.csv",header = TRUE)
#add target variable for levels of endorsement of transition planning quality
FlanaganFinalData$TRNSQuality <- c(1,2,3,4)
View(FlanaganFinalData)
View(FlanaganFinalData)
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60,127)))))
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
trns_items$trnsqual <-trns_items %>% sum(c(1:46))
trns_items$trnsqual <-sum(trns_items[,1:46])
View(trns_items)
trns_items$trnsqual <- rowSums(trns_items[,c(1:46)])
summarise(trns_items$trnsqual)
summarise(trns_items)
View(trns_items)
reticulate::repl_python()
library(reticulate)
from sklearn.preprocessing import
from feature_engine.discretisers import EqualWidthDiscretiser
quit
py_install("sklearn")
library(reticulate)
py_install("sklearn")
py_install("scikit-learn")
py_install("feature-engine")
py_install("feature_engine")
reticulate::repl_python()
# Equal-Width Discretization of trnsqual to 4 bins
# type "quit" in console to end the instance and to return to R.
#reticulated requires that you call data from R with "r." appended to the name as down below.
#It's currently only accurate when similarity score => 95
from sklearn.preprocessing import
from feature_engine.discretisers import EqualWidthDiscretiser
from sklearn.preprocessing import KBinsDiscretizer
from feature_engine.discretisers import EqualWidthDiscretiser
from feature_engine import EqualWidthDiscretiser
discredtizer = KBinsDiscretizer(N_BINS=4,encode='ordinal',strategy='uniform')
discredtizer = KBinsDiscretizer(n_bins=4,encode='ordinal',strategy='uniform')
QUIT
quit
install.packages("infotheo")
library(infotheo)
# equal width discretize trnsqual vector
trns_items$trnsqual <- discretize(trns_items$trnsqual,disc="equalwidth",nbins=3)
View(trns_items)
#run PCA
prcomp(trns_items,scale. = TRUE)
#run PCA
trns_pca <- prcomp(trns_items,scale. = TRUE)
rm(pca)
rm(PC1)
rm(PC1_scores)
rm(PC1_scores_ordered)
rm(pca_var)
rm(pca_var_perc)
rm(pizzas)
rm(data)
rm(pca_1_2)
#get eigen values from the PCA
trns_pca_eigen <- trns_pca$sdev^2
#get eigen values from the PCA
trns_pca$eigenvalues <- trns_pca$sdev^2
rm(trns_pca_eigen)
print(trns_pca$eigenvalues)
#plot components with eigenvalue over 1 to see how they divide the data into clusters depending upon the discrete levels of trnsqual
trns_pca_maxpcs <- data.frame(trns_pca$x[, 1:8])
plot(trns_pca$x[,1],
trns_pca$x[,2],
trns_pca$x[,3],
trns_pca$x[,4],
trns_pca$x[,5],
trns_pca$x[,6],
trns_pca$x[,7],
trns_pca$x[,8])
plot(trns_pca_maxpcs$x[,1],
trns_pca_maxpcs$x[,2],
trns_pca_maxpcs$x[,3],
trns_pca_maxpcs$x[,4],
trns_pca_maxpcs$x[,5],
trns_pca_maxpcs$x[,6],
trns_pca_maxpcs$x[,7],
trns_pca_maxpcs$x[,8])
#plot components with eigenvalue over 1 to see how they divide the data into clusters depending upon the discrete levels of trnsqual
trns_pca_maxpcs <- data.frame(trns_pca$x[, 1:2])
View(trns_pca_maxpcs)
plot(trns_pca$x[,1],
trns_pca$x[,2])
print(trns_pca$x)
#plot components with eigenvalue over 1 to see how they divide the data into clusters depending upon the discrete levels of trnsqual
trns_pca_maxpcs <- data.frame(trns_pca$x[, 1:3])
plot(trns_pca$x[,1],
trns_pca$x[,2],
trns_pca$x[,3])
#run PCA
trns_pca <- prcomp(trns_items,scale. = FALSE)
#get eigen values from the PCA
trns_pca$eigenvalues <- trns_pca$sdev^2
plot(trns_pca$x[,1],
trns_pca$x[,2])
#Calculate the percentage of variation within each principal component
trns_pca_var <- trns_pca$sdev^2 #get variance
trns_pca_var_perc <- round(trns_pca_var/sum(trns_pca_var)*100,1) # each PC variance
barplot(trns_pca_var_perc,main= "PC Variation Plot", xlab="Principal Components", ylab="Percentage of Variance",ylim = c(0,100))
plot(trns_pca$x[,1],
trns_pca$x[,2])
rm(trns_pca_maxpcs)
#plot components with eigenvalue over 1 to see how they divide the data into clusters depending upon the discrete levels of trnsqual
trns_pca_maxpcs2 <- data.frame(trns_pca$x[, 1:2])
trns_pca_maxpcs3 <- data.frame(trns_pca$x[, 1:3])
trns2d <- plot(trns_pca_maxpcs2$x[,1],
trns_pca_maxpcs2$x[,2])
#plot components with eigenvalue over 1 to see how they divide the data into clusters depending upon the discrete levels of trnsqual
trns_pca_maxpcs2 <- data.frame(trns_pca$x[, 1:2])
trns_pca_maxpcs3 <- data.frame(trns_pca$x[, 1:3])
trns2d <- plot(trns_pca$x[,1],
trns_pca$x[,2])
trns3d <- scatterplot3d::scatterplot3d((trns_pca[,1:3]))
trns3d <- scatterplot3d::scatterplot3d((trns_pca$x[,1:3]))
trns2d <- plot(trns_pca$x[,1],
trns_pca$x[,2])
#Calculate the percentage of variation within each principal component
trns_pca_var <- trns_pca$sdev^2 #get variance
trns_pca_var_perc <- round(trns_pca_var/sum(trns_pca_var)*100,1) # each PC variance
#plot the PC variance
barplot(trns_pca_var_perc,main= "PC Variation Plot", xlab="Principal Components", ylab="Percentage of Variance",ylim = c(0,100))
#assign weights to features in each PCA (loadings), with an array of loadings for each PC being an Eigenvector
PC1 <- trns_pca$rotation[,1]
PC1_scores <- abs(PC1)
PC1_scores_ordered <- sort(PC1_scores,decreasing = TRUE)
names(PC1_scores_ordered)
ggplot(data,aes(x=data$cal,y=data$mois,color = data$brand)) +
geom_point() +
labs(title = "SQIs Most Differentating Transition Planning")
ggplot(data,aes(x=SQI34$cal,y=data$sSQI36,color = trns_items$trnsqual)) +
geom_point() +
labs(title = "SQIs Most Differentating Transition Planning")
ggplot(data,aes(x=trns_itrms$SQI34,y=trns_items$SQI36,color = trns_items$trnsqual)) +
geom_point() +
labs(title = "SQIs Most Differentating Transition Planning")
ggplot(data,aes(x=trns_items$SQI34,y=trns_items$SQI36,color = trns_items$trnsqual)) +
geom_point() +
labs(title = "SQIs Most Differentating Transition Planning")
#differentiate between levels of target variable using most important features
ggplot(trns_items,aes(x=trns_items$SQI34,y=trns_items$SQI36,color = trns_items$trnsqual)) +
geom_point() +
labs(title = "SQIs Most Differentating Transition Planning")
#differentiate between levels of target variable using most important features
ggplot(trns_items,aes(x=SQI34,y=SQI36,color = trnsqual)) +
geom_point() +
labs(title = "SQIs Most Differentating Transition Planning")
PC1 <- trns_pca$rotation[,1]
PC1_scores <- abs(PC1)
PC1_scores_ordered <- sort(PC1_scores,decreasing = TRUE)
names(PC1_scores_ordered)
#make the target null so that PCA can tell identify the discrete levels
trns_items_orginal <- trns_items #keep one without null for later
ggplot(trns_items_orginal, aes(x=trns_items_orginal$SQI34,y=trns_items_orginal$SQI36, color = trns_items_orginal$trnsqual) +
geom_point() +
labs(title = "SQIs Differentating Levels of Transition Planning Quality"))
#differentiate between levels of target variable using most important features
ggplot(trns_items_orginal, aes(x=trns_items_orginal$SQI34,y=trns_items_orginal$SQI36, color = trns_items_orginal$trnsqual) +
geom_point())
#differentiate between levels of target variable using most important features
ggplot(trns_items_orginal,
aes(x=trns_items_orginal$SQI34,
y=trns_items_orginal$SQI36,
color = trns_items_orginal$trnsqual)) +
geom_point()
ggplot(trns_items_orginal,
aes(x=SQI34,
y=SQI36,
color = trnsqual)) +
geom_point()
View(trns_items_orginal)
#get cleaned data if session looses environment
FlanaganFinalData <- read.csv("FlanaganFinalData.csv",header = TRUE)
#make the target null so that PCA can tell identify the discrete levels
trns_items_orginal <- trns_items #keep one without null for later
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
QI2_items <- as_tibble(select(all_items,c(5:12)))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
#make the target null so that PCA can tell identify the discrete levels
trns_items_orginal <- trns_items #keep one without null for later
rm(trns_items_orginal)
#make the target null so that PCA can tell identify the discrete levels
trns_items2 <- trns_items #keep one without null for later
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
QI2_items <- as_tibble(select(all_items,c(5:12)))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
#create total trns score (which is target variable for PCA)
trns_items$trnsqual <- as.numeric(rowSums(trns_items[,c(1:46)]))
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
QI2_items <- as_tibble(select(all_items,c(5:12)))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
#create total trns score (which is target variable for PCA)
trns_items$trnsqual <- as.numeric(rowSums(trns_items[,c(1:46)]))
#get cleaned data if session looses environment
FlanaganFinalData <- read.csv("FlanaganFinalData.csv",header = TRUE)
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
QI2_items <- as_tibble(select(all_items,c(5:12)))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
#create total trns score (which is target variable for PCA)
trns_items$trnsqual <- as.numeric(rowSums(trns_items[,c(1:46)]))
#equal width discretize trnsqual vector to 3 bins representing the ordinal scale of the 46 features
trns_items$trnsqual <- discretize(trns_items$trnsqual,disc="equalwidth",nbins=3)
#get cleaned data if session looses environment
FlanaganFinalData <- read.csv("FlanaganFinalData.csv",header = TRUE)
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
QI2_items <- as_tibble(select(all_items,c(5:12)))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
#create total trns score (which is target variable for PCA)
trns_items$trnsqual <- as.numeric(rowSums(trns_items[,c(1:46)]))
#equal width discretize trnsqual vector to 3 bins representing the ordinal scale of the 46 features
trnsqual <- discretize(trns_items$trnsqual,disc="equalwidth",nbins=3)
#get cleaned data if session looses environment
FlanaganFinalData <- read.csv("FlanaganFinalData.csv",header = TRUE)
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
QI2_items <- as_tibble(select(all_items,c(5:12)))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
#create total trns score (which is target variable for PCA)
trns_items$trnsqual <- as.numeric(rowSums(trns_items[,c(1:46)]))
#equal width discretize trnsqual vector to 3 bins representing the ordinal scale of the 46 features
discretize(trns_items$trnsqual,disc="equalwidth",nbins=3)
#equal width discretize trnsqual vector to 3 bins representing the ordinal scale of the 46 features
trns_items$trnsqual <- discretize(trns_items$trnsqual,disc="equalwidth",nbins=3)
#get cleaned data if session looses environment
FlanaganFinalData <- read.csv("FlanaganFinalData.csv",header = TRUE)
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
QI2_items <- as_tibble(select(all_items,c(5:12)))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
#create total trns score (which is target variable for PCA)
trns_items$trnsqual <- as.numeric(rowSums(trns_items[,c(1:46)]))
#equal width discretize trnsqual vector to 3 bins representing the ordinal scale of the 46 features
trnsqual <- discretize(trns_items$trnsqual,disc="equalwidth",nbins=3)
trns_items$trnsqual <- trnsqual$X
trns_items$trnsqual <- as.character(trns_items$trnsqual)
#make the target null so that PCA can tell identify the discrete levels
trns_items2 <- trns_items #keep one without null for later
trns_items <- trns_items[,"trnsqual" := NULL]
trns_items <- trns_items[,trnsqual := NULL]
trns_items$trnsqual <- as.numeric(trns_items$trnsqual)
trns_items <- trns_items[,trnsqual := NULL]
trns_items <- trns_items[,trnsqual] := NULL)
trns_items <- trns_items[, trnsqual := NULL]
#get cleaned data if session looses environment
FlanaganFinalData <- read.csv("FlanaganFinalData.csv",header = TRUE)
#subset
all_items <- as_tibble(na.omit((select(FlanaganFinalData,c(7:60)))))
QI2_items <- as_tibble(select(all_items,c(5:12)))
trns_items <- as_tibble(select(all_items,c(1:4,13:54)))
#create total trns score (which is target variable for PCA)
trns_items$trnsqual <- as.numeric(rowSums(trns_items[,c(1:46)]))
#equal width discretize trnsqual vector to 3 bins representing the ordinal scale of the 46 features
trnsqual_dis <- discretize(trns_items$trnsqual,disc="equalwidth",nbins=3)
trns_items$trnsqual <- trnsqual_dis$X
#make the target null so that PCA can tell identify the discrete levels
trns_items2 <- trns_items #keep one without null for later
#make the target null so that PCA can tell identify the discrete levels
trns_items2 <- copy(trns_items) #keep one without null for later
trns_items <- trns_items[, trnsqual := NULL]
trns_items <- trns_items[, 47:= NULL]
trns_items <- trns_items[, "trnsqual":= NULL]
data <- data.table(read.csv("PCAtestdata.csv"))
data <- data[1:87,]
pizzas <- copy(data)
pizzas <- pizzas[, brand := NULL] #make target null because we want the analyses to tell us the different types
